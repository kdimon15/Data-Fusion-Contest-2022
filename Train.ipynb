{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import pickle\n",
    "import catboost\n",
    "from catboost import Pool, CatBoostClassifier, CatBoostRanker\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from psutil import virtual_memory\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickstream_path = 'data/clickstream.csv'\n",
    "transactions_path = 'data/transactions.csv'\n",
    "matching_path = 'data/train_matching.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_negatives = 70\n",
    "    num_easiest_examples = 7\n",
    "\n",
    "    class First_model:\n",
    "        depth = 5\n",
    "        iterations = 5000\n",
    "        \n",
    "    class Second_model:\n",
    "        depth = 9\n",
    "        iterations = 18000\n",
    "        lr = 0.02\n",
    "\n",
    "    seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_comb_features(dataframe):\n",
    "    for x in range(24):\n",
    "        dataframe[f'diff_hours_{x}'] = dataframe[f'click_h_{x}'] - dataframe[f'trans_h_{x}']\n",
    "\n",
    "all_dicts = {}\n",
    "clickstream = pd.read_csv(clickstream_path)\n",
    "\n",
    "all_dicts['rtk_le'] = LabelEncoder().fit(clickstream['user_id'])\n",
    "clickstream['user_id'] = all_dicts['rtk_le'].transform(clickstream['user_id'])+1\n",
    "clickstream_dtypes = {'user_id':np.int16, 'cat_id':np.int16, 'new_uid':np.int32}\n",
    "clickstream = clickstream.astype(clickstream_dtypes)\n",
    "\n",
    "clickstream['timestamp'] = pd.to_datetime(clickstream['timestamp'])\n",
    "clickstream['date'] = clickstream['timestamp'].dt.date.astype('category')\n",
    "clickstream['hour'] = clickstream['timestamp'].dt.hour.astype('category')\n",
    "clickstream['weekday'] = clickstream['timestamp'].dt.dayofweek.astype('category')\n",
    "\n",
    "clickstream_embed = clickstream.pivot_table(index = 'user_id', \n",
    "                            values=['timestamp'],\n",
    "                            columns=['cat_id'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "clickstream_embed2 = clickstream.pivot_table(index = 'user_id', \n",
    "                            values=['timestamp'],\n",
    "                            columns=['date'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "clickstream_embed3 = clickstream.pivot_table(index = 'user_id', \n",
    "                            values=['new_uid'],\n",
    "                            aggfunc=['nunique']).fillna(0)\n",
    "clickstream_embed4 = clickstream.groupby('user_id')['timestamp'].apply(lambda x: np.max(x) - np.min(x)).dt.days.astype('int16').to_frame()\n",
    "clickstream_embed5 = clickstream.pivot_table(index = 'user_id', \n",
    "                            values=['timestamp'],\n",
    "                            columns=['weekday','hour'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "clickstream_embed.columns = [f'rtk-{str(i[0])}-{str(i[2])}' for i in clickstream_embed.columns]\n",
    "clickstream_embed2.columns = [f'rtk-{str(i[0])}-{str(i[2])}' for i in clickstream_embed2.columns]\n",
    "clickstream_embed3.columns = [f'rtk-{str(i[0])}-{str(i[1])}' for i in clickstream_embed3.columns]\n",
    "clickstream_embed4.columns = [f'rtk-max_date_diff' for i in clickstream_embed4.columns]\n",
    "clickstream_embed5.columns = [f'rtk-{str(i[0])}-weekday-{str(i[2])}-nhour-{str(i[3])}' for i in clickstream_embed5.columns]\n",
    "clickstream_embed = clickstream_embed.merge(clickstream_embed2, left_on='user_id', right_index=True).merge(\n",
    "                                            clickstream_embed3, left_on='user_id', right_index=True).merge(\n",
    "                                            clickstream_embed4, left_on='user_id', right_index=True).merge(\n",
    "                                            clickstream_embed5, left_on='user_id', right_index=True)\n",
    "clickstream_embed.loc[0] = np.empty(len(clickstream_embed.columns))\n",
    "\n",
    "clickstream['hour'] = clickstream['timestamp'].dt.hour\n",
    "cl_sv = pd.pivot_table(clickstream, index='user_id', columns='hour', values = 'timestamp', aggfunc = 'count').fillna(0)\n",
    "cl_sv['summs'] = cl_sv.sum(axis=1)\n",
    "for i in cl_sv.columns[:-1]:\n",
    "    cl_sv[i] /= cl_sv['summs']\n",
    "cl_sv.columns = ['click_h_'+ str(i) for i in cl_sv.columns]\n",
    "del clickstream, clickstream_embed2, clickstream_embed3, clickstream_embed4, clickstream_embed5\n",
    "gc.collect()\n",
    "\n",
    "dtype_clickstream = list()\n",
    "for x in clickstream_embed.dtypes.tolist():\n",
    "    if x == 'int64' or x == 'int32' or x == 'int16':\n",
    "        dtype_clickstream.append('int16')\n",
    "    elif x == 'float64' or x == 'float32':\n",
    "        dtype_clickstream.append('float32')\n",
    "    else:\n",
    "        dtype_clickstream.append('object')\n",
    "\n",
    "dtype_clickstream = dict(zip(clickstream_embed.columns.tolist(),dtype_clickstream))\n",
    "clickstream_embed = clickstream_embed.astype(dtype_clickstream)\n",
    "\n",
    "\n",
    "transactions = pd.read_csv(transactions_path)\n",
    "transactions['transaction_dttm'] = pd.to_datetime(transactions['transaction_dttm'])\n",
    "all_dicts['bank_le'] = LabelEncoder().fit(transactions['user_id'])\n",
    "transactions['user_id'] = all_dicts['bank_le'].transform(transactions['user_id'])+1\n",
    "transactions_dtypes = {'user_id':np.int16, 'mcc_code':np.int16, 'currency_rk':np.int8}\n",
    "transactions = transactions.astype(transactions_dtypes)\n",
    "\n",
    "transactions['date'] = transactions['transaction_dttm'].dt.date.astype('category')\n",
    "transactions['hour'] = transactions['transaction_dttm'].dt.hour.astype('category')\n",
    "transactions['weekday'] = transactions['transaction_dttm'].dt.dayofweek.astype('category')\n",
    "\n",
    "bankclient_embed = transactions.pivot_table(index = 'user_id',\n",
    "                            values=['transaction_amt'],\n",
    "                            columns=['mcc_code'],\n",
    "                            aggfunc=['sum', 'mean', 'count']).fillna(0)\n",
    "bankclient_embed.columns = [f'{str(i[0])}-{str(i[2])}' for i in bankclient_embed.columns]\n",
    "bankclient_embed2 = transactions.pivot_table(index = 'user_id', \n",
    "                            values=['transaction_amt'],\n",
    "                            columns=['currency_rk'],\n",
    "                            aggfunc=['sum', 'mean', 'count']).fillna(0)\n",
    "bankclient_embed2.columns = [f'{str(i[0])}-{str(i[2])}' for i in bankclient_embed2.columns]\n",
    "bankclient_embed3 = transactions.pivot_table(index = 'user_id', \n",
    "                            values=['transaction_dttm'],\n",
    "                            columns=['date'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "bankclient_embed3.columns = [f'{str(i[0])}-{str(i[2])}' for i in bankclient_embed3.columns]\n",
    "bankclient_embed4 = transactions.pivot_table(index = 'user_id', \n",
    "                            values=['transaction_dttm'],\n",
    "                            columns=['weekday','hour'],\n",
    "                            aggfunc=['count']).fillna(0)\n",
    "bankclient_embed4.columns = [f'bnk-{str(i[0])}-weekday-{str(i[2])}-nhour-{str(i[3])}' for i in bankclient_embed4.columns]\n",
    "bankclient_embed5 = transactions.groupby('user_id')['transaction_dttm'].apply(lambda x: np.max(x) - np.min(x)).dt.days.astype('int16').to_frame()\n",
    "bankclient_embed5.columns = [f'bnk-max_date_diff' for i in bankclient_embed5.columns]\n",
    "bankclient_embed = bankclient_embed.merge(bankclient_embed2, left_on='user_id', right_index=True\n",
    "                                        ).merge(bankclient_embed3, left_on='user_id', right_index=True\n",
    "                                                ).merge(bankclient_embed4, left_on='user_id', right_index=True\n",
    "                                                    ).merge(bankclient_embed5, left_on='user_id', right_index=True)\n",
    "\n",
    "tr_sv = pd.pivot_table(transactions, index='user_id', columns='hour', values = 'transaction_amt', aggfunc = 'count').fillna(0)\n",
    "tr_sv['summs'] = tr_sv.sum(axis=1)\n",
    "for i in tr_sv.columns[:-1]:\n",
    "    tr_sv[i] /= tr_sv['summs']\n",
    "tr_sv.columns = ['trans_h_'+ str(i) for i in tr_sv.columns]\n",
    "\n",
    "del transactions, bankclient_embed2, bankclient_embed3, bankclient_embed4\n",
    "gc.collect()\n",
    "\n",
    "dtype_bankclient = list()\n",
    "for x in bankclient_embed.dtypes.tolist():\n",
    "    if x == 'int64' or x == 'int32' or x == 'int16':\n",
    "        dtype_bankclient.append('int16')\n",
    "    elif x == 'float64' or x == 'float32':\n",
    "        dtype_bankclient.append('float32')\n",
    "    else:\n",
    "        dtype_bankclient.append('object')\n",
    "    \n",
    "dtype_bankclient = dict(zip(bankclient_embed.columns.tolist(),dtype_bankclient))\n",
    "bankclient_embed = bankclient_embed.astype(dtype_bankclient)\n",
    "\n",
    "main_train_df = pd.read_csv(matching_path)\n",
    "main_train_df['bank'] = all_dicts['bank_le'].transform(main_train_df['bank'])+1\n",
    "main_train_df = main_train_df[main_train_df['rtk']!='0']\n",
    "main_train_df['rtk'] = all_dicts['rtk_le'].transform(main_train_df['rtk'])+1\n",
    "main_train_df['bank+rtk'] = main_train_df['bank'].astype('str')+'+'+main_train_df['rtk'].astype('str')\n",
    "train = main_train_df\n",
    "\n",
    "k = CFG.num_negatives\n",
    "cor_dict = train.set_index('bank')['rtk'].to_dict()\n",
    "\n",
    "train_bank_ids = train['bank']\n",
    "train_rtk_ids = train[train.bank.isin(train_bank_ids)]['rtk'].drop_duplicates()\n",
    "df_train = pd.DataFrame(train_bank_ids, columns=['bank'])\n",
    "df_train['rtk'] = df_train['bank'].apply(lambda x: [cor_dict[x]] + train_rtk_ids.sample(k, random_state=x+CFG.seed).values.tolist())\n",
    "\n",
    "df_train = df_train.explode('rtk')\n",
    "\n",
    "train['bank+rtk'] = train['bank'].astype('str')+'_'+train['rtk'].astype('str')\n",
    "df_train['bank+rtk'] = df_train['bank'].astype('str')+'_'+df_train['rtk'].astype('str')\n",
    "df_train['target'] = df_train['bank+rtk'].isin(train['bank+rtk']).astype('int')\n",
    "\n",
    "df_train.drop_duplicates('bank+rtk', inplace=True)\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "X_train=df_train.merge(bankclient_embed, how='left', left_on='bank', right_index=True\n",
    "                    ).merge(clickstream_embed, how='left', left_on='rtk', right_index=True\n",
    "                        ).merge(cl_sv, how='left', left_on='rtk', right_index=True\n",
    "                            ).merge(tr_sv, how='left', left_on='bank', right_index=True\n",
    "                                ).fillna(0)\n",
    "\n",
    "make_comb_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c606bf0ced3472e905f4a467726190e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.090298\n",
      "0:\tlearn: 0.6133920\ttotal: 228ms\tremaining: 3m 47s\n",
      "200:\tlearn: 0.2707968\ttotal: 32.9s\tremaining: 2m 10s\n",
      "400:\tlearn: 0.2619088\ttotal: 1m 1s\tremaining: 1m 32s\n",
      "600:\tlearn: 0.2538106\ttotal: 1m 30s\tremaining: 1m\n",
      "800:\tlearn: 0.2475027\ttotal: 1m 58s\tremaining: 29.5s\n",
      "999:\tlearn: 0.2420566\ttotal: 2m 26s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ad02f850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CatBoostClassifier(\n",
    "    depth=CFG.First_model.depth,\n",
    "    iterations=CFG.First_model.iterations,\n",
    "    random_seed=CFG.seed,\n",
    ")\n",
    "feature_list = X_train.drop(['bank', 'rtk', 'target', 'bank+rtk'], axis=1).columns.tolist()\n",
    "clf.fit(Pool(X_train[feature_list], X_train['target']), verbose=200, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['predicts'] = clf.predict_proba(X_train[feature_list])[:, 1]\n",
    "\n",
    "for x in range(CFG.num_easiest_examples):\n",
    "    X_train = X_train[~X_train['predicts'].isin(X_train[X_train['target']==0].groupby('bank')['predicts'].apply(min).values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bb/jzxxldrn52l0stzqmszjx6840000gn/T/ipykernel_11930/1502152050.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.drop(bad_cols, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "feature_imp = clf.get_feature_importance()\n",
    "bad_cols = [feature_list[i] for i in range(len(feature_list)) if feature_imp[i] < 0.025]\n",
    "X_train.drop(bad_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02192ad5be5047d993b36a43413360f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 66.8ms\tremaining: 13.3s\n",
      "199:\ttotal: 11.8s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRanker at 0x1bfce1df0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CatBoostRanker(\n",
    "    loss_function='YetiRank',\n",
    "    learning_rate=CFG.Second_model.lr,\n",
    "    depth=CFG.Second_model.depth,\n",
    "    iterations=CFG.Second_model.iterations,\n",
    "    custom_metric=['MRR'],\n",
    "    random_seed=CFG.seed,\n",
    ")\n",
    "feature_list = X_train.drop(['bank', 'rtk', 'target', 'predicts', 'bank+rtk'], axis=1).columns.tolist()\n",
    "clf.fit(Pool(X_train[feature_list], X_train['target'], group_id=X_train['bank']), verbose=200, plot=True)\n",
    "clf.save_model('catboost.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de5b5158f0f473875a99b085e9673109bb8ddd7077bae4aacc1691ae83c7246d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
